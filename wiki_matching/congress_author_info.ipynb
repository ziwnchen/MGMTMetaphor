{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle\n",
    "import re\n",
    "from wikidata.client import Client\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a full list of congress member data from the current website:https://github.com/unitedstates/congress-legislators?tab=readme-ov-file\n",
    "url = 'https://theunitedstates.io/congress-legislators/legislators-historical.json'\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "current_url = 'https://theunitedstates.io/congress-legislators/legislators-current.json'\n",
    "current_response = requests.get(current_url)\n",
    "current_data = current_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the json file to a pandas dataframe witht the following columns:\n",
    "# bioguide_id, wikidata_id, name_first, name_last, birthday, gender, term_start, term_end, type, state, party\n",
    "def convert_json_to_df(data):\n",
    "    # create an empty list to store the data\n",
    "    data_list = []\n",
    "    # iterate through the json file to extract the data\n",
    "    for i in range(len(data)):\n",
    "        bioguide_id = data[i]['id'].get('bioguide', None)\n",
    "        wikidata_id = data[i]['id'].get('wikidata', None)\n",
    "        name_first = data[i]['name'].get('first', None)\n",
    "        name_last = data[i]['name'].get('last', None)\n",
    "        birthday = data[i]['bio'].get('birthday', None)\n",
    "        gender = data[i]['bio'].get('gender', None)\n",
    "        for term in data[i]['terms']:\n",
    "            term_start = term.get('start', None)\n",
    "            term_end = term.get('end', None)\n",
    "            term_type = term.get('type', None)\n",
    "            state = term.get('state', None)\n",
    "            party = term.get('party', None)\n",
    "            # append the data to the list\n",
    "            data_list.append([bioguide_id, wikidata_id, name_first, name_last, birthday, gender, term_start, term_end, term_type, state, party])\n",
    "    # convert the list to a pandas dataframe\n",
    "    df = pd.DataFrame(data_list, columns=['bioguide_id', 'wikidata_id', 'name_first', 'name_last', 'birthday','gender', 'term_start', 'term_end', 'term_type', 'state', 'party'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = convert_json_to_df(data)\n",
    "meta_df['term_start_year'] = meta_df['term_start'].apply(lambda x: int(x.split('-')[0]))\n",
    "meta_df['term_end_year'] = meta_df['term_end'].apply(lambda x: int(x.split('-')[0]))\n",
    "\n",
    "current_meta_df = convert_json_to_df(current_data)\n",
    "current_meta_df['term_start_year'] = current_meta_df['term_start'].apply(lambda x: int(x.split('-')[0]))\n",
    "current_meta_df['term_end_year'] = current_meta_df['term_end'].apply(lambda x: int(x.split('-')[0]))\n",
    "\n",
    "# concatenate the two dataframes\n",
    "meta_df = pd.concat([meta_df, current_meta_df], axis=0)\n",
    "meta_df = meta_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which congress terms are in the meta data\n",
    "def year_to_congress(start_year, end_year):\n",
    "    if start_year > end_year:\n",
    "        raise ValueError(\"Start year must be less than or equal to end year.\")\n",
    "\n",
    "    # The first Congress began in 1789\n",
    "    FIRST_CONGRESS_YEAR = 1789\n",
    "    first_congress = (start_year - FIRST_CONGRESS_YEAR) // 2 + 1\n",
    "    last_congress = (end_year - FIRST_CONGRESS_YEAR) // 2 + 1\n",
    "\n",
    "    if first_congress < 1:\n",
    "        first_congress = 1\n",
    "\n",
    "    return list(range(first_congress, last_congress + 1))\n",
    "\n",
    "# select members if they served in the 81st to 114th congress\n",
    "def select_congress(congress_ls):\n",
    "    if_select = False\n",
    "    for congress in congress_ls:\n",
    "        if congress>=81 and congress<=114:\n",
    "            if_select = True\n",
    "            break\n",
    "    return if_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['congress'] = meta_df.progress_apply(lambda x: year_to_congress(x['term_start_year'], x['term_end_year']), axis=1)\n",
    "meta_df['if_select'] = meta_df['congress'].apply(lambda x: select_congress(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_members = list(set(meta_df[meta_df['if_select'] == True]['wikidata_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract SES Information from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def property_value_extraction(entity, prop):\n",
    "    claims = entity.data.get('claims', {})\n",
    "    property_claims = claims.get(prop, []) # usually start with p\n",
    "    values = []\n",
    "    for claim in property_claims:\n",
    "        mainsnak = claim.get('mainsnak', {})\n",
    "        datavalue = mainsnak.get('datavalue', {})\n",
    "        value = datavalue.get('value', {}).get('id', None)\n",
    "        if value:\n",
    "            values.append(value)\n",
    "    return values\n",
    "\n",
    "def identifier_extraction(entity, prop):\n",
    "    claims = entity.data.get('claims', {})\n",
    "    property_claims = claims.get(prop, []) # usually start with p\n",
    "    values = []\n",
    "    for claim in property_claims:\n",
    "        mainsnak = claim.get('mainsnak', {})\n",
    "        datavalue = mainsnak.get('datavalue', {})\n",
    "        value = datavalue.get('value', None)\n",
    "        if value:\n",
    "            values.append(value)\n",
    "    return values\n",
    "\n",
    "def time_extraction(entity, prop):\n",
    "    claims = entity.data.get('claims', {})\n",
    "    property_claims = claims.get(prop, []) # usually start with p\n",
    "    values = []\n",
    "    for claim in property_claims:\n",
    "        mainsnak = claim.get('mainsnak', {})\n",
    "        datavalue = mainsnak.get('datavalue', {})\n",
    "        value = datavalue.get('value', {}).get('time', None)\n",
    "        if value:\n",
    "            values.append(value)\n",
    "    return values\n",
    "\n",
    "# sometimes, education information is nested\n",
    "def get_education(entity):\n",
    "    # if degree or major is nested in education\n",
    "    institution_values = []\n",
    "    degree_values = []\n",
    "    major_values = []\n",
    "\n",
    "    claims = entity.data.get('claims', {})\n",
    "    education_claims = claims.get('P69', []) # usually start with p\n",
    "    for education in education_claims:\n",
    "        # main entry: institution\n",
    "        mainsnak = education.get('mainsnak', {})\n",
    "        datavalue = mainsnak.get('datavalue', {})\n",
    "        value = datavalue.get('value', {}).get('id', None)\n",
    "        if value:\n",
    "            institution_values.append(value)\n",
    "        # search qualifiers for degree and major, in case they are nested\n",
    "        qualifiers = education.get('qualifiers', {})\n",
    "        if \"P512\" in qualifiers:\n",
    "            degree_id = qualifiers[\"P512\"][0].get('datavalue', {}).get('value', {}).get('id')\n",
    "            degree_values.append(degree_id)\n",
    "        if \"P812\" in qualifiers:\n",
    "            major_id = qualifiers[\"P812\"][0].get('datavalue', {}).get('value', {}).get('id')\n",
    "            major_values.append(major_id)\n",
    "    \n",
    "    # search for degree and major if they are not nested\n",
    "    degree_values += property_value_extraction(entity, 'P512')\n",
    "    major_values += property_value_extraction(entity, 'P812')\n",
    "\n",
    "    # remove duplicates\n",
    "    institution_values = list(set(institution_values))\n",
    "    degree_values = list(set(degree_values))\n",
    "    major_values = list(set(major_values))\n",
    "\n",
    "    return institution_values, degree_values, major_values    \n",
    "\n",
    "def get_SES_characteristics(entity):\n",
    "    # gender\n",
    "    gender_values = property_value_extraction(entity, 'P21')\n",
    "    # birth date\n",
    "    birth_date_values = time_extraction(entity, 'P569')\n",
    "    # death date\n",
    "    death_date_values = time_extraction(entity, 'P570')\n",
    "    # citizenship\n",
    "    citizenship_values = property_value_extraction(entity, 'P27')\n",
    "    # ethinic group\n",
    "    ethinic_group_values = property_value_extraction(entity, 'P172')\n",
    "    # education\n",
    "    education_values, degree_values, major_values = get_education(entity)\n",
    "    # student of (this will be sparse) -- if students of famous economists are included, this will be useful\n",
    "    student_of_values = property_value_extraction(entity, 'P1066')\n",
    "    # occupation\n",
    "    occupation_values = property_value_extraction(entity, 'P106')\n",
    "    # employer in the past\n",
    "    employer_values = property_value_extraction(entity, 'P108')\n",
    "    # political party (this will be sparse)\n",
    "    political_party_values = property_value_extraction(entity, 'P102')\n",
    "    # ideology (this will be sparse)\n",
    "    ideology_values = property_value_extraction(entity, 'P1142')\n",
    "    # bio guide ID\n",
    "    bio_id = identifier_extraction(entity, 'P1157')\n",
    "\n",
    "    # dictionary\n",
    "    SES_characteristics = {\"gender\": gender_values, \"birth_date\": birth_date_values, \"death_date\": death_date_values,\n",
    "                            \"citizenship\": citizenship_values, \"ethinic_group\": ethinic_group_values, \"education\": education_values,\n",
    "                            \"degree\": degree_values,\"major\": major_values, \"student_of\": student_of_values, \"occupation\": occupation_values,\n",
    "                            \"employer\": employer_values, \"political_party\": political_party_values, \"ideology\": ideology_values}\n",
    "    return SES_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the SES characteristics\n",
    "data_path =\"/zfs/projects/faculty/amirgo-management/congress/\"\n",
    "ses_df = pd.read_pickle(data_path + \"congress_ses_characteristics_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_members = list(set(selected_members) - set(ses_df['qid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/413 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [03:19<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# for each entity, get SES characteristics\n",
    "# total_qids = list(selected_members)\n",
    "total_qids = additional_members\n",
    "\n",
    "client = Client()\n",
    "total_ses_characteristics = []\n",
    "error_qids = []\n",
    "for qid in tqdm(total_qids):\n",
    "    try:\n",
    "        entity = client.get(qid, load=True)\n",
    "        SES_characteristics = get_SES_characteristics(entity)\n",
    "        SES_characteristics[\"qid\"] = qid\n",
    "        total_ses_characteristics.append(SES_characteristics)\n",
    "        # wait for 0.2 second\n",
    "        time.sleep(0.2)\n",
    "    except:\n",
    "        print(\"Error: \", qid)\n",
    "        error_qids.append(qid)\n",
    "        time.sleep(30) # wait for 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df_additional = pd.DataFrame(total_ses_characteristics)\n",
    "ses_df = pd.concat([ses_df, ses_df_additional], axis=0)\n",
    "ses_df = ses_df.reset_index(drop=True)\n",
    "ses_df.to_pickle(data_path + \"congress_ses_characteristics_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the SES characteristics\n",
    "# data_path =\"/zfs/projects/faculty/amirgo-management/congress/\"\n",
    "# ses_df = pd.DataFrame(total_ses_characteristics)\n",
    "# ses_df.to_pickle(data_path + \"congress_ses_characteristics_new.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetch labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all qids in columns to its corresponding label\n",
    "gender_qids = list(set(ses_df['gender'].sum()))\n",
    "citizenship_qids = list(set(ses_df['citizenship'].sum()))\n",
    "ethinic_group_qids = list(set(ses_df['ethinic_group'].sum()))\n",
    "education_qids = list(set(ses_df['education'].sum()))\n",
    "degree_qids = list(set(ses_df['degree'].sum()))\n",
    "major_qids = list(set(ses_df['major'].sum()))\n",
    "student_of_qids = list(set(ses_df['student_of'].sum()))\n",
    "occupation_qids = list(set(ses_df['occupation'].sum()))\n",
    "employer_qids = list(set(ses_df['employer'].sum()))\n",
    "political_party_qids = list(set(ses_df['political_party'].sum()))\n",
    "ideology_qids = list(set(ses_df['ideology'].sum()))\n",
    "\n",
    "total_qids = gender_qids + citizenship_qids + ethinic_group_qids + education_qids + degree_qids + major_qids + student_of_qids + occupation_qids + employer_qids + political_party_qids + ideology_qids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_labels(qids):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    labels = {}\n",
    "\n",
    "    # Construct SPARQL query for the current batch\n",
    "    qid_filter = \" \".join([f\"wd:{qid}\" for qid in qids])\n",
    "    query = f\"\"\"\n",
    "    SELECT ?item ?itemLabel WHERE {{\n",
    "        VALUES ?item {{ {qid_filter} }}\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    try:\n",
    "        # Execute the query\n",
    "        results = sparql.query().convert()\n",
    "        \n",
    "        # Parse results\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            qid = result[\"item\"][\"value\"].split(\"/\")[-1]  # Extract QID from full URI\n",
    "            label = result[\"itemLabel\"][\"value\"]  # Extract the label\n",
    "            labels[qid] = label\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {chunk}. Error: {e}\")\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing QID Chunks: 100%|██████████| 40/40 [00:52<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process QIDs in chunks\n",
    "chunk_size = 100\n",
    "qid_to_label_dict = {}\n",
    "chunks = np.array_split(total_qids, len(total_qids) // chunk_size + 1)\n",
    "\n",
    "for chunk in tqdm(chunks, desc=\"Processing QID Chunks\"):\n",
    "    labels = fetch_labels(chunk.tolist())  # Convert NumPy array to list\n",
    "    qid_to_label_dict.update(labels)\n",
    "    time.sleep(1)  # Sleep for 1 second to avoid hitting the Wikidata API too quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"qid_to_label_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(qid_to_label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df['gender'] = ses_df['gender'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['citizenship'] = ses_df['citizenship'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['ethinic_group'] = ses_df['ethinic_group'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['education'] = ses_df['education'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['degree'] = ses_df['degree'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['major'] = ses_df['major'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['student_of'] = ses_df['student_of'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['occupation'] = ses_df['occupation'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['employer'] = ses_df['employer'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['political_party'] = ses_df['political_party'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])\n",
    "ses_df['ideology'] = ses_df['ideology'].apply(lambda x: [qid_to_label_dict[qid] for qid in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df['gender'] = ses_df['gender'].apply(lambda x: x[0] if len(x) == 1 else x)\n",
    "ses_df['citizenship'] = ses_df['citizenship'].apply(lambda x: x[0] if len(x) == 1 else x)\n",
    "ses_df['ethinic_group'] = ses_df['ethinic_group'].apply(lambda x: x[0] if len(x) == 1 else x)\n",
    "ses_df['political_party'] = ses_df['political_party'].apply(lambda x: x[0] if len(x) == 1 else x)\n",
    "ses_df['ideology'] = ses_df['ideology'].apply(lambda x: x[0] if len(x) == 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df.to_pickle(data_path + \"congress_ses_characteristics_labelled_new.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Indicator Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/zfs/projects/faculty/amirgo-management/congress/\"\n",
    "ses_df = pd.read_pickle(data_path + \"congress_ses_characteristics_new.pkl\")\n",
    "ses_df_labelled = pd.read_pickle(data_path + \"congress_ses_characteristics_labelled_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bschools = pd.read_csv(\"/zfs/projects/faculty/amirgo-management/opus/processed/business_schools.csv\")\n",
    "bschools['qid'] = bschools['business_school'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# business education\n",
    "# if someone went to business school: if education institution is in the list of business schools; or if degree is business\n",
    "business_degree = set(['Q798129', 'Q12580940','Q191701'])\n",
    "business_schools = set(bschools['qid'].tolist())\n",
    "def if_biz_ed(row):\n",
    "    education = row['education']\n",
    "    degree = row['degree']\n",
    "    if len(education) == 0 and len(degree) == 0:\n",
    "        return \"Missing\"\n",
    "    else:\n",
    "        if_biz = False\n",
    "        for edu in education:\n",
    "            if edu in business_schools:\n",
    "                if_biz = True\n",
    "                break\n",
    "        for deg in degree:\n",
    "            if deg in business_degree:\n",
    "                if_biz = True\n",
    "                break\n",
    "        return str(if_biz)\n",
    "\n",
    "ses_df['if_business_ed'] = ses_df.apply(lambda x: if_biz_ed(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# college education (a corse classification)\n",
    "# if the education institution has 'university' or 'college' in the name;\n",
    "college_degrees = ['bachelor', 'master', 'doctor', 'phd', 'ba', 'ma', 'bs', 'ms', 'mba', 'jd', 'llb', 'llm', 'md']\n",
    "def if_college_ed(row):\n",
    "    education = row['education']\n",
    "    degree = row['degree']\n",
    "    if len(education) == 0 and len(degree) == 0:\n",
    "        return \"Missing\"\n",
    "    else:\n",
    "        if_college = False\n",
    "        for edu in education:\n",
    "            if 'university' in edu.lower() or 'college' in edu.lower():\n",
    "                if_college = True\n",
    "                break\n",
    "        for deg in degree:\n",
    "            deg = deg.lower()\n",
    "            if any(col in deg for col in college_degrees):\n",
    "                if_college = True\n",
    "                break\n",
    "        return str(if_college)\n",
    "\n",
    "ses_df_labelled['if_college_ed'] = ses_df_labelled.apply(lambda x: if_college_ed(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# business occupation\n",
    "occupations = ['businessperson','business executive','entrepreneur', 'businessman', 'business',\n",
    " 'investor', 'executive', 'ceo', 'banker','manager', 'consultant','chief executive officer', 'finance', 'managing', 'executive','investment']\n",
    "\n",
    "def if_bis_occuptation(row):\n",
    "    occupation = row['occupation']\n",
    "    if len(occupation) == 0:\n",
    "        return \"Missing\"\n",
    "    else:\n",
    "        if_bis = False\n",
    "        for occ in occupation:\n",
    "            occ = occ.lower()\n",
    "            for x in occupations:\n",
    "                if x in occ:\n",
    "                    if_bis = True\n",
    "                    break\n",
    "        return str(if_bis)\n",
    "\n",
    "ses_df_labelled['if_business_occupation'] = ses_df_labelled.apply(lambda x: if_bis_occuptation(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df_labelled['if_business_ed']  =ses_df['if_business_ed']\n",
    "ses_df_labelled.to_pickle(data_path + \"congress_ses_characteristics_labelled_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df_labelled['birth_date'] = ses_df_labelled['birth_date'].apply(lambda x: x[0] if len(x) > 0 else \"Missing\")\n",
    "ses_df_labelled['birth_year'] = ses_df_labelled['birth_date'].apply(lambda x: int(x[1:5]) if x != \"Missing\" else \"Missing\")\n",
    "ses_df_labelled[['qid','birth_year','gender','if_college_ed','if_business_occupation','if_business_ed']].to_csv(data_path + \"congress_ses_characteristics_labelled_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male      3010\n",
       "female     277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses_df_labelled['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_business_ed\n",
       "False      3008\n",
       "True        162\n",
       "Missing     117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses_df['if_business_ed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_business_occupation\n",
       "False    2749\n",
       "True      538\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses_df_labelled['if_business_occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_college_ed\n",
       "True       2986\n",
       "False       184\n",
       "Missing     117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses_df_labelled['if_college_ed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data = pd.read_csv(data_path + \"congress_ses_characteristics_labelled_subset.csv\")\n",
    "meta_df = meta_df.merge(wiki_data, left_on='wikidata_id', right_on='qid', how='left')\n",
    "meta_df.to_csv(data_path + \"congress_meta_data_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = meta_df[meta_df['if_select']==True] # only select those who are selected (ie in 81st to 114th congress)\n",
    "meta_df['congress'] = meta_df.progress_apply(lambda x: year_to_congress(x['term_start_year'],x['term_end_year']),axis=1)\n",
    "meta_df_flat = meta_df.explode('congress').reset_index(drop=True).copy()\n",
    "meta_df_flat = meta_df_flat[['bioguide_id','wikidata_id','name_first','name_last','birthday','gender_x','congress','state',\n",
    "'if_college_ed','if_business_occupation','if_business_ed']].drop_duplicates()\n",
    "meta_df_flat = meta_df_flat[(meta_df_flat['congress']>=81) & (meta_df_flat['congress']<=114)]\n",
    "meta_df_flat.dropna(subset=['if_business_occupation'],inplace=True)\n",
    "meta_df_flat.rename(columns={\"gender_x\":\"gender\",\"name_first\":\"firstname\",\"name_last\":\"lastname\"},inplace=True)\n",
    "meta_df_flat['lastname'] = meta_df_flat['lastname'].apply(lambda x: x.upper())\n",
    "meta_df_flat['firstname'] = meta_df_flat['firstname'].apply(lambda x: x.upper())\n",
    "meta_df_flat.reset_index(drop=True,inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
